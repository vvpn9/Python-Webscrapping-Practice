# Scrapy整体架构
Scrapy（引擎）用来处理整个系统的数据流

Scheduler（调度器）用来接受引擎发送的请求，压入队列之中，并在引擎再次请求的时候给予返回

Downloader（下载器）用于下载网页内容，并讲网页内容返回给爬虫（spider）

Spiders（爬虫）用于从特定的网页中提取自己需要的信息

Pipeline（项目管道）负责处理爬虫从网页中提取的实体，主要的功能室持久化实体，验证实体的有效性，清楚不需要的信息。
当页面被爬虫解析之后，将被发送到项目管道，并经过几个特定的次序处理数据。

Downloader Middlewares（下载中间器）位于Scrapy引擎和下载器之间的框架，主要是处理引擎和下载器之间的请求和响应。

Spider Middlewares（爬虫中间器）介于Scrapy引擎和爬虫之间的框架，主要是负责处理爬虫的响应输入和请求输出。

Scheduler Middlewares（调度中间器）介于Scrapy引擎和调度之间的框架，负责Scrapy引擎发送到调度的请求和响应

# Scrapy大概运行流程
1. 引擎从调度器中取出一个链接（url）用于接下来的抓取
2. 引擎把url封装成一个请求（request）传递给下载器
3. 下载器把资源下载下来，并封装成应答包（response）
4. 爬虫解析应答包
5. 解析出实体（item），并交给实体管道进行进一步处理
6. 解析出得是链接，则把链接交给调度器等待抓取